{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "100321_translocations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1zPZeSa-MEtr2LQAzphR8eD5FLcSkfG3A",
      "authorship_tag": "ABX9TyPBn47Uf5OMWc9ju7/OU9FR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarySelifanova/PlantLIMEs/blob/master/100321_translocations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSfRLlGLizNV"
      },
      "source": [
        "# Find translocations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRcwELRGjYHZ",
        "outputId": "fa9b29e4-8128-48ce-e864-a8ae5c8ab622"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVT8vzdbiDcy"
      },
      "source": [
        "### **Install and import modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpWxiOWRWtQ8"
      },
      "source": [
        "!pip install bio\n",
        "!pip install XlsxWriter\n",
        "from Bio import SeqIO\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import xlsxwriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O52PogCCispQ"
      },
      "source": [
        "### **Find all possible words of length k in the alignment file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecH3RZNnkumq"
      },
      "source": [
        "def find_k_mers(file, k): #file – alignment, k – kmer length\n",
        "    k_mers = [] #empty list for all possible (not unique) kmers\n",
        "    \n",
        "    with open(file, \"rU\") as handle:  \n",
        "        for record in SeqIO.parse(handle, \"fasta\"): #iterating through sequences in the alignment file\n",
        "            \n",
        "            test_str = str(record.seq) #test_str – one sequence; res – list of kmers of particular length k\n",
        "            res = [test_str[x:y] for x, y in combinations(range(len(test_str) + 1), 2) if len(test_str[x:y]) == k and '-' not in test_str[x:y]]\n",
        "            k_mers.extend(res) #add values \n",
        "    \n",
        "    k_mers_set = set(k_mers) #unique kmers of particular length\n",
        "    return k_mers_set"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YmWNTvilWIb"
      },
      "source": [
        "### **Create a list of matrices with kmers starts; one matrix for each unique kmer word**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5F7SWzYlQA6"
      },
      "source": [
        "def create_small_matrices(file, k_mers_set): #file – alignment, k_mers_set – unique kmers of particular length\n",
        "    \n",
        "    m_list = [] #empty list for dataframes (each dataframe - for unique kmer of particular length)\n",
        "    k_list = [] #empty list for according kmers \n",
        "    num_seq = len([1 for line in open(file) if line.startswith(\">\")]) #num_seq – number of sequences\n",
        "\n",
        "    for i in range(len(list(k_mers_set))): #iterating through number of k-mers from the set of particular length\n",
        "\n",
        "        kmer = list(k_mers_set)[i] #one kmer (one word)\n",
        "        starts_set = [] #empty kmer's starts list\n",
        "        starts_list = []\n",
        "\n",
        "        with open(file, \"rU\") as handle:\n",
        "\n",
        "            for record in SeqIO.parse(handle, \"fasta\"): #iterating through each record in the alignmnet\n",
        "        \n",
        "                test_str = str(record.seq) #test_str – one sequence in the alignmnet\n",
        "                starts = [m.start() for m in re.finditer(kmer, test_str)] #starts list in one sequence\n",
        "                starts_set.extend(starts)   #add to kmer's starts list  \n",
        "                starts_list.append(starts)\n",
        "        \n",
        "        starts_set = set(starts_set) #no coordinate duplicates in kmer starts in the alignment ...\n",
        "        starts_set = list(starts_set) #... but still it's a list ...\n",
        "        starts_set = sorted(starts_set) #... sorted list\n",
        "        if len(starts_set) > 1: #if there are more than 1 possible start in the kmer\n",
        "        \n",
        "          df = pd.DataFrame(np.zeros((num_seq, len(starts_set)))) #df FOR 1 KMER with zeroes, num_col = num unique starts; num_row = num seq in the alignment;\n",
        "          df.columns = starts_set # rename columns as starts\n",
        "        \n",
        "          for s in range(len(starts_list)):  #iterating through number of kmer's starts (list of lists: starts of kmer in each sequence)\n",
        "\n",
        "            l = starts_list[s] #l – starts list in one sequence\n",
        "            for j in range(len(l)): #iterating through number of starts in l \n",
        "                df.loc[s, l[j]] = 1 #set 1 for this start in df\n",
        "\n",
        "          df[starts_set] = df[starts_set].apply(pd.to_numeric) #values should be integers (df[starts_set] = df, starts_set - list with colunm names)\n",
        "          m_list.append(df) #add kmer df to all dfs list\n",
        "          k_list.append(kmer)\n",
        "\n",
        "    return m_list, k_list"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6rJoE0pxAl1"
      },
      "source": [
        "***m_list – one for each kmer length***\n",
        "\n",
        "*   *m_list =  = [[df1],[df2],...]*\n",
        "*   *df1 = [1, 25, ...]*\n",
        "*   *1, 25, ... – all possible starts (in all seqs of alignment)* of one word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbevIPbKycP8"
      },
      "source": [
        "### **Calculate correlations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "152pFxN2yeVj"
      },
      "source": [
        "def correlations(m_list, k_list, outfile, threshold):  #m_list – see above, outfile – result table, threshold – level of correlation\n",
        "    \n",
        "    hit_list = [] #empty list for lists of anticorrelating pairs for each kmer\n",
        "    for mat in range(len(m_list)): #iterating through matrices for each unique kmer (of the length k)\n",
        "\n",
        "        l = m_list[mat] #l - matrix for one kmer ('mr')\n",
        "        corr_matrix = l.corr() #create correlation matrix for one unique kmer (l) of particular size (kmer)\n",
        "        hits = [(corr_matrix.columns[x], corr_matrix.columns[y], corr_matrix.at[int(corr_matrix.columns[x]),int(corr_matrix.columns[y])]) for x, y in zip(*np.where(corr_matrix.values < - 0.8))] #filter basing on correlation\n",
        "        kmer = k_list[mat] #corresponding kmer (word), hits – anticorrelating pairs of positions for one kmer ('mr')\n",
        "\n",
        "        pairs = [] #empty list for anticorrelating pairs\n",
        "        used = [] #empty list for used cols and rows \n",
        "        \n",
        "        for h in hits: \n",
        "            \n",
        "            col_name = h[1]\n",
        "            row_name = h[0]\n",
        "            value = h[2]\n",
        "            \n",
        "            if col_name not in used or row_name not in used: #take unique pairs from hits and put them into 'pairs' list\n",
        "                \n",
        "                pair = str(kmer) + '_' + str(min(col_name, row_name)) + '_' + str(max(col_name, row_name)) + '_' + str(value) + '_' + str(abs(col_name - row_name)) #forming a pair\n",
        "                pairs.append(pair) #adding correlated pair \n",
        "            \n",
        "                used.append(col_name)\n",
        "                used.append(row_name)\n",
        "        \n",
        "        hit_list.append(pairs) #append list of anticorrelating pairs of one kmer to a general hit list \n",
        "        \n",
        "    hit_list_checked = [] #create a list of kmer-pos pairs without empty lists (when a kmer doesn't have anticorrelating positions)\n",
        "    for l in hit_list:\n",
        "        if l:\n",
        "            hit_list_checked.append(l)\n",
        "    return hit_list_checked"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F3KJKtOTt-p"
      },
      "source": [
        "### **Create result tables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUJbmNsRT-TU"
      },
      "source": [
        "def translocations(file, outfile, threshold):\n",
        "\n",
        "      res_df_list = []\n",
        "      for k in range(1,5): \n",
        "     \n",
        "          k_mers_set = find_k_mers(file, k) #all posible words of length k in the alignment 'file'\n",
        "          m_list, k_list = create_small_matrices(file, k_mers_set) #list of matrices (1 m – 1 kmer word; k_list – list of corresponding kmers)\n",
        "          hit_list_checked = correlations(m_list, k_list, outfile, threshold) #list of 'pairs' lists, where each 'pairs' –  for one kmer\n",
        "\n",
        "          #create empty lists for columns\n",
        "          word = []\n",
        "          pos1 = []\n",
        "          pos2 = []\n",
        "          corr = []\n",
        "          leap = []\n",
        "\n",
        "          #fill columns with values  \n",
        "          for l in range(len(hit_list_checked)):\n",
        "                \n",
        "              pairs = hit_list_checked[l]  #list of anticorrelating pairs          \n",
        "              for p in range(len(pairs)): #iterate through pairs \n",
        "                    \n",
        "                  pair = pairs[p].split('_')\n",
        "                  word.append(pair[0])\n",
        "                  pos1.append(pair[1])\n",
        "                  pos2.append(pair[2])\n",
        "                  corr.append(pair[3])\n",
        "                  leap.append(pair[4])\n",
        "\n",
        "          #crate dataframe and fill it with values   \n",
        "          columns = ['kmer', 'pos1', 'pos2', 'corr', 'leap']\n",
        "          res_df = pd.DataFrame(columns=columns)\n",
        "          res_df['kmer'] = word\n",
        "          res_df['pos1'] = pos1\n",
        "          res_df['pos2'] = pos2\n",
        "          res_df['corr'] = corr\n",
        "          res_df['leap'] = leap\n",
        "\n",
        "          res_df_list.append(res_df)\n",
        "      \n",
        "      # Create a Pandas Excel writer using XlsxWriter as the engine\n",
        "      writer = pd.ExcelWriter(outfile, engine='xlsxwriter')\n",
        "\n",
        "      # Write each dataframe to a different worksheet\n",
        "      res_df_list[0].to_excel(writer, sheet_name='len=1')\n",
        "      res_df_list[1].to_excel(writer, sheet_name='len=2')\n",
        "      res_df_list[2].to_excel(writer, sheet_name='len=3')\n",
        "      res_df_list[3].to_excel(writer, sheet_name='len=4')\n",
        "\n",
        "      # Close the Pandas Excel writer and output the Excel file\n",
        "      writer.save()\n",
        "      \n",
        "      return res_df_list   "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_-D7fVJuGQC",
        "outputId": "f4fce002-96f2-4b0b-daa8-8b92a3e3660f"
      },
      "source": [
        "file = '/content/drive/MyDrive/Translocations/H1N1_H3N2.1557.AA.aligned.1str.fasta'\n",
        "outfile = '/content/drive/MyDrive/Translocations/H1N1_H3N2.1557.AA.aligned.1str_final.xlsx'\n",
        "threshold = -0.8\n",
        "\n",
        "res_df_list = translocations(file, outfile, threshold)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: 'U' mode is deprecated\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: 'U' mode is deprecated\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "429TCmCgV2sB"
      },
      "source": [
        "#save res_df_list to file \n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/Translocations/res_df_list.txt', 'wb') as fp:\n",
        "    pickle.dump(res_df_list, fp)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j683S4RZWC64"
      },
      "source": [
        "#and get it back\n",
        "import pickle\n",
        "\n",
        "with open ('/content/drive/MyDrive/Translocations/res_df_list.txt', 'rb') as fp:\n",
        "   rdl  = pickle.load(fp)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x132h1RSNzqC"
      },
      "source": [
        "# Tune final tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMEydAYHOCBc"
      },
      "source": [
        "### **Tune coordinates (position + 1)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuCC77FR2LTv"
      },
      "source": [
        "pos_cols = ['pos1', 'pos2']\n",
        "for d in rdl:\n",
        "    d['pos1'] = pd.to_numeric(d['pos1']) \n",
        "    d['pos2'] = pd.to_numeric(d['pos2'])\n",
        "    d[pos_cols] += 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdjEYtXAWj1N"
      },
      "source": [
        "### **Remove duplicates**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSoY7X4rN8Hh",
        "outputId": "30e7ef3a-f4c1-43b6-fa42-5d4eed7d8726"
      },
      "source": [
        "print(rdl[0].shape)\n",
        "print(rdl[1].shape)\n",
        "print(rdl[2].shape)\n",
        "print(rdl[3].shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(136, 5)\n",
            "(386, 5)\n",
            "(39, 5)\n",
            "(3, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwmpicWxIZca"
      },
      "source": [
        "**NGKL > NGKL**\n",
        "\n",
        "*   NGK > NGK (65-407), GKL > GKL (66-408); \n",
        "*   NG > NG(65-407), GK > GK(66-408), KL > KL(67-409)\n",
        "*   N > N, G > G, K > K, L > L\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryDVZipkWn-8",
        "outputId": "4779bd56-b67c-4b22-8914-59f7b398d085"
      },
      "source": [
        "#subtract kmers (where k = 4) from 1,2,3 -mers\n",
        "for index4, row4 in rdl[3].iterrows():\n",
        "    \n",
        "    p1 = int(row4['pos1'])\n",
        "    p2 = int(row4['pos2'])\n",
        "    print(p1, p2)\n",
        "    \n",
        "    for index3, row3 in rdl[2].iterrows():\n",
        "\n",
        "        if int(row3['pos1']) == p1 and int(row3['pos2']) == p2:\n",
        "            rdl[2].drop(index3, inplace=True)\n",
        "        if int(row3['pos1']) == p1 + 1 and int(row3['pos2']) == p2 + 1:\n",
        "            rdl[2].drop(index3, inplace=True)\n",
        "            \n",
        "    for index2, row2 in rdl[1].iterrows():\n",
        "\n",
        "        if int(row2['pos1']) == p1 and int(row2['pos2']) == p2:\n",
        "          rdl[1].drop(index2, inplace=True)\n",
        "          print('start1', row2['pos1'], row2['pos2'])\n",
        "\n",
        "        if int(row2['pos1']) == p1 + 1 and int(row2['pos2']) == p2 + 1:\n",
        "            rdl[1].drop(index2, inplace=True)\n",
        "            print('start2', row2['pos1'], row2['pos2'])\n",
        "\n",
        "        if int(row2['pos1']) == p1 + 2 and int(row2['pos2']) == p2 + 2:\n",
        "            rdl[1].drop(index2, inplace=True)\n",
        "            print('start3', row2['pos1'], row2['pos2'])\n",
        "\n",
        "    for index1, row1 in rdl[0].iterrows():\n",
        "\n",
        "        if int(row1['pos1']) == p1 and int(row1['pos2']) == p2:\n",
        "            rdl[0].drop(index1, inplace=True)\n",
        "        if int(row1['pos1']) == p1 + 1 and int(row1['pos2']) == p2 + 1:\n",
        "            rdl[0].drop(index1, inplace=True)\n",
        "        if int(row1['pos1']) == p1 + 2 and int(row1['pos2']) == p2 + 2:\n",
        "            rdl[0].drop(index1, inplace=True)\n",
        "        if int(row1['pos1']) == p1 + 3 and int(row1['pos2']) == p2 + 3:\n",
        "            rdl[0].drop(index1, inplace=True)                          "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65 407\n",
            "409 525\n",
            "135 551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxW5IotiKRBt"
      },
      "source": [
        "**NGK > NGK (65-407)** \n",
        "\n",
        "*   NG > NG (65-407), GK > GK (66-408)\n",
        "*   N > N, G > G, K > K"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtj7SYpiKAvn"
      },
      "source": [
        "#subtract kmers (where k = 4) from 1,2,3 -mers\n",
        "for index3, row3 in rdl[2].iterrows():\n",
        "    \n",
        "    p1 = int(row3['pos1'])\n",
        "    p2 = int(row3['pos2'])\n",
        "    print(p1, p2)\n",
        "    \n",
        "    for index2, row2 in rdl[1].iterrows():\n",
        "\n",
        "        if int(row2['pos1']) == p1 and int(row2['pos2']) == p2:\n",
        "          rdl[1].drop(index2, inplace=True)\n",
        "          print('start1', row2['pos1'], row2['pos2'])\n",
        "\n",
        "        if int(row2['pos1']) == p1 + 1 and int(row2['pos2']) == p2 + 1:\n",
        "          rdl[1].drop(index2, inplace=True)\n",
        "          print('start2', row2['pos1'], row2['pos2'])    \n",
        "\n",
        "\n",
        "    for index1, row1 in rdl[0].iterrows():\n",
        "\n",
        "        if int(row1['pos1']) == p1 and int(row1['pos2']) == p2:\n",
        "            rdl[0].drop(index1, inplace=True)\n",
        "        if int(row1['pos1']) == p1 + 1 and int(row1['pos2']) == p2 + 1:\n",
        "            rdl[0].drop(index1, inplace=True)\n",
        "        if int(row1['pos1']) == p1 + 2 and int(row1['pos2']) == p2 + 2:\n",
        "            rdl[0].drop(index1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vygB3JfELPss"
      },
      "source": [
        "**NG > NG (65-407)** \n",
        "\n",
        "*   N > N (65-407), G > G (66-408)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nZSkAB-KHGZ"
      },
      "source": [
        "#subtract kmers (where k = 2) from 1-mers\n",
        "for index2, row2 in rdl[1].iterrows():\n",
        "    \n",
        "    p1 = int(row2['pos1'])\n",
        "    p2 = int(row2['pos2'])\n",
        "    print(p1, p2)\n",
        "\n",
        "    for index1, row1 in rdl[0].iterrows():\n",
        "        if int(row1['pos1']) == p1 and int(row1['pos2']):\n",
        "            rdl[0].drop(index1, inplace=True)\n",
        "        if int(row1['pos1']) == p1 + 1 and int(row1['pos2']) == p2 + 1:\n",
        "            rdl[0].drop(index1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "NIRTw7eBetep",
        "outputId": "6cdcf600-09c9-4324-a97c-5219f693fa47"
      },
      "source": [
        "rdl[3]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kmer</th>\n",
              "      <th>pos1</th>\n",
              "      <th>pos2</th>\n",
              "      <th>corr</th>\n",
              "      <th>leap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NGKL</td>\n",
              "      <td>65</td>\n",
              "      <td>407</td>\n",
              "      <td>-0.9923224536590236</td>\n",
              "      <td>342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KLNR</td>\n",
              "      <td>409</td>\n",
              "      <td>525</td>\n",
              "      <td>-0.8748574099479502</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VASS</td>\n",
              "      <td>135</td>\n",
              "      <td>551</td>\n",
              "      <td>-0.9783986661292924</td>\n",
              "      <td>416</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   kmer  pos1  pos2                 corr leap\n",
              "0  NGKL    65   407  -0.9923224536590236  342\n",
              "1  KLNR   409   525  -0.8748574099479502  116\n",
              "2  VASS   135   551  -0.9783986661292924  416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkl6fJBpWq-k"
      },
      "source": [
        "### **Add translocation statistics (00, 01, 10, 11)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoki8XWaW1x3",
        "outputId": "65644967-e925-470e-d539-e56102283357"
      },
      "source": [
        "for i in range(len(rdl)):\n",
        "\n",
        "  d = rdl[i]\n",
        "  k = i + 1 \n",
        "\n",
        "  sum00_l = [] \n",
        "  sum01_l = []\n",
        "  sum10_l = []\n",
        "  sum11_l = []\n",
        "\n",
        "  for index, row in d.iterrows():\n",
        "\n",
        "      p1 = int(row['pos1'])\n",
        "      p2 = int(row['pos2'])\n",
        "      w = row['kmer']\n",
        "\n",
        "      sum00 = 0\n",
        "      sum01 = 0\n",
        "      sum10 = 0\n",
        "      sum11 = 0\n",
        "\n",
        "      file = '/content/drive/MyDrive/Translocations/H1N1_H3N2.1557.AA.aligned.1str.fasta'\n",
        "      with open(file, \"rU\") as handle:\n",
        "\n",
        "              for record in SeqIO.parse(handle, \"fasta\"): #iterating through each record in the alignmnet\n",
        "          \n",
        "                  test_str = str(record.seq) #test_str – one sequence in the alignmnet\n",
        "                  test_kmer1 = test_str[p1-1:p1-1+k]\n",
        "                  test_kmer2 = test_str[p2-1:p2-1+k]\n",
        "\n",
        "                  if test_kmer1 == w:\n",
        "                    if test_kmer2 == w:\n",
        "                      sum11 += 1\n",
        "                    else:\n",
        "                      sum10 += 1\n",
        "                  else:\n",
        "                    if test_kmer2 == w:\n",
        "                      sum01 += 1\n",
        "                    else:\n",
        "                      sum00 +=1\n",
        "\n",
        "      sum00_l.append(sum00)\n",
        "      sum01_l.append(sum01)\n",
        "      sum10_l.append(sum10)\n",
        "      sum11_l.append(sum11)\n",
        "\n",
        "  d['00'] = sum00_l\n",
        "  d['01'] = sum01_l\n",
        "  d['10'] = sum10_l\n",
        "  d['11'] = sum11_l"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: 'U' mode is deprecated\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0K0BztCgx-P"
      },
      "source": [
        "rdl[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GgdU5-XeNwe"
      },
      "source": [
        "outfile = '/content/drive/MyDrive/Translocations/H1N1_H3N2.1557.AA.aligned.1str_tuned.xlsx'\n",
        "# Create a Pandas Excel writer using XlsxWriter as the engine\n",
        "writer = pd.ExcelWriter(outfile, engine='xlsxwriter')\n",
        "\n",
        "# Write each dataframe to a different worksheet\n",
        "rdl[0].to_excel(writer, sheet_name='len=1')\n",
        "rdl[1].to_excel(writer, sheet_name='len=2')\n",
        "rdl[2].to_excel(writer, sheet_name='len=3')\n",
        "rdl[3].to_excel(writer, sheet_name='len=4')\n",
        "\n",
        "# Close the Pandas Excel writer and output the Excel file\n",
        "writer.save()"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}